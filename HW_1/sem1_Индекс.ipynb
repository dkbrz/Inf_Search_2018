{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 1 Индекс\n",
    "\n",
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### чтение файла \n",
    "- конструкция __with open__ (recommended)\n",
    "- конструкция __open + close__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = 'fpath.txt'\n",
    "\n",
    "# одним массивом  \n",
    "with open(fpath, 'r') as f:  \n",
    "    text = f.read() \n",
    "\n",
    "#по строкам, в конце каждой строки \\n  \n",
    "with open(fpath, 'r') as f:   \n",
    "    text = f.readlines() \n",
    "\n",
    "#по строкам, без \\n   \n",
    "with open(fpath, 'r') as f:   \n",
    "    text = f.read().splitlines() \n",
    "    \n",
    "#not reccomended  \n",
    "file = open(txt_fpath, 'r')  \n",
    "text = file.read()    \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### работа с файлами и папками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.path  \n",
    "путь до файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# возвращает полный путь до папки/файла по имени файла / папки\n",
    "print(os.path.abspath('fpath.txt'))\n",
    "\n",
    "# возвращает имя файла / папки по полному пути до него\n",
    "print(os.path.basename('/your/path/to/folder/with/fpath.txt'))\n",
    "\n",
    "# проверить существование директории - True / False\n",
    "print(os.path.exists('your/path/to/any/folder/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.listdir  \n",
    "возвращает список файлов в данной директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/your/path/to/folder/with/folders/'\n",
    "os.listdir(main_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "сделаем пути абсолютными, чтобы наш код не зависел от того, где лежит этот файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[main_dir + fpath for fpath in os.listdir(main_dir)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "не забывайте исключать системные директории, такие как .DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[main_dir + fpath for fpath in os.listdir(main_dir) if not '.DS_Store' in fpath]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.walk\n",
    "root - начальная директория  \n",
    "dirs - список поддиректорий (папок)   \n",
    "files - список файлов в этих поддиректориях  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/your/path/to/folder/with/folders/'\n",
    "\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for name in files:\n",
    "        print(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __os.walk__ возвращает генератор, это значит, что получить его элементы можно только проитерировавшись по нему  \n",
    "но его легко можно превратить в list и увидеть все его значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(os.walk(main_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Обратный индекс \n",
    "\n",
    "Сам по себе обратный индекс не может осуществлять поиск, для этого необходимо добавить к нему определенную метрику. Это не совсем очевидная задача, поэтому немного отложим ее. А сейчас посмотрим, что полезного можно вытащить из индекса.    \n",
    "По сути, индекс - это информация о частоте встречаемости слова в каждом документе.   \n",
    "Из этого можно понять, например:\n",
    "1. какое слово является самым часто употребимым / редким\n",
    "2. какие слова встречаются всегда вместе. Так можно парсить твиттер, fb, форумы и отлавливать новые устойчивые выражения в речи\n",
    "3. какой документ является самым большим / маленьким (очень изощренный способ, когда есть _len_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__: \n",
    "получите обратный индекс для коллекция документов.    \n",
    "Перед этим постройте матрицу терм-документ и сделайте функцию булева поиска, которая по запросу будет возвращать 5 релевантных документов.   \n",
    "В качестве коллекции возьмите сценарий сезонов сериала Друзья. Одна серия - один документ.\n",
    "\n",
    "[download_friends_corpus](https://yadi.sk/d/k_M7n63A3adGSz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этапы:   \n",
    "    1. получить коллекцию документов\n",
    "    2. для каждого файла коллекции сделать необходимую на ваш взгляд предобработку\n",
    "    3. получить матрицу терм-документ, написать функцию поиска по ней\n",
    "    4. получить обратный индекс в виде словаря, где ключ - нормализованное слово, \n",
    "    значение - список файлов, в которых это слово встречается\n",
    "    5. вывести кусочек индекса в виде таблицы \n",
    "    6. сделать анализ обратного индекса. Это задание принимается в виде кода и ответов на вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Friends/wedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напоминание:    \n",
    "> При итерации по списку вы можете помимо самого элемента получить его порядковый номер    \n",
    "``` for i, element in enumerate(your_list): ...  ```    \n",
    "Иногда для получения элемента делают так -  ``` your_list[i] ```, старайтесь этого избегать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "main_dir = './Friends/'\n",
    "files_list = []\n",
    "\n",
    "### пройдитесь по всем папкам коллекции и соберите все пути .txt файлов\n",
    "### _check : в коллекции должно быть 165 файлов\n",
    "\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for name in files:\n",
    "        files_list.append(os.path.abspath(os.path.join(root, name)))\n",
    "\n",
    "len(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import string\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_doc_matrix(files_list):\n",
    "    n = len(files_list)\n",
    "    dictionary = {}\n",
    "    term_doc_matrix = []\n",
    "    for number, file in tqdm(list(enumerate(files_list))):\n",
    "        with open(file, 'r', encoding='utf-8') as f:\n",
    "            text = Counter(morph.parse(word.strip(string.punctuation))[0].normal_form for word in f.read().replace(u'\\ufeff','').split())\n",
    "            for word in text:\n",
    "                if word in dictionary:\n",
    "                    term_doc_matrix[dictionary[word]][number] += text[word]\n",
    "                else:\n",
    "                    dictionary[word] = len(dictionary)\n",
    "                    term_doc_matrix.append(np.zeros(n))\n",
    "                    term_doc_matrix[dictionary[word]][number] += text[word]\n",
    "    return dictionary, term_doc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c14c11688247bca5da1784ed44a1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=165), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### постройте матрицу терм-документ\n",
    "dictionary, term_doc_matrix = get_term_doc_matrix(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import luqum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _result(tree, term_doc_matrix, dictionary):\n",
    "    if type(tree) is luqum.tree.Group:\n",
    "        return _result(tree.children[0], term_doc_matrix, dictionary)\n",
    "    elif hasattr(tree, 'op'):\n",
    "        if tree.op == 'AND':\n",
    "            ...\n",
    "            return result\n",
    "        elif tree.op == 'OR':\n",
    "            result = np.zeros(len(term_doc_matrix[0]))\n",
    "            ...\n",
    "            return result\n",
    "        elif tree.op == 'NOT ':\n",
    "            return [bool(1 - i) for i in _result(tree.children[0], term_doc_matrix, dictionary)]\n",
    "    elif type(tree) is luqum.tree.Word:\n",
    "        word = tree.value.lower()\n",
    "        if word in dictionary:\n",
    "            return term_doc_matrix[dictionary[word]]>0\n",
    "        else:\n",
    "            return np.zeros(len(term_doc_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _result(tree, term_doc_matrix, dictionary):\n",
    "    if type(tree) is luqum.tree.Group:\n",
    "        return _result(tree.children[0], term_doc_matrix, dictionary)\n",
    "    elif hasattr(tree, 'op'):\n",
    "        if tree.op == 'AND':\n",
    "            result = np.ones(len(term_doc_matrix[0]))\n",
    "            for i in tree.children:\n",
    "                r2 = _result(i, term_doc_matrix, dictionary)\n",
    "                result = [value and r2[key] for key, value in enumerate(result)]\n",
    "            return result\n",
    "        elif tree.op == 'OR':\n",
    "            result = np.zeros(len(term_doc_matrix[0]))\n",
    "            for i in tree.children:\n",
    "                r2 = _result(i, term_doc_matrix, dictionary)\n",
    "                result = [value or r2[key] for key, value in enumerate(result)]\n",
    "            return result\n",
    "        elif tree.op == 'NOT ':\n",
    "            return [bool(1 - i) for i in _result(tree.children[0], term_doc_matrix, dictionary)]\n",
    "    elif type(tree) is luqum.tree.Word:\n",
    "        word = tree.value.lower()\n",
    "        if word in dictionary:\n",
    "            return term_doc_matrix[dictionary[word]]>0\n",
    "        else:\n",
    "            return np.zeros(len(term_doc_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### напишите функцию булева поиска по построенной матрице\n",
    "\n",
    "def boolean_search(query, term_doc_matrix, dictionary) -> list:\n",
    "    \"\"\"\n",
    "    Produces a Boolean search according with the term-document matrix\n",
    "    :return: list of first 5 relevant documents\n",
    "    \"\"\"\n",
    "    query = query.replace('&','AND').replace('НЕ','NOT').replace('ИЛИ','OR')#.replace('(','( ').replace(')',' )')\n",
    "    tree = luqum.parser.parser.parse(query)\n",
    "    #print(tree)\n",
    "    result = _result(tree, term_doc_matrix, dictionary)\n",
    "    #result = _result(query, term_doc_matrix, dictionary)\n",
    "    return [key for key, value in enumerate(result) if value == True]\n",
    "\n",
    "\n",
    "#запросы \n",
    "input_text = [\n",
    "    'Моника & Фиби & Рэйчел & Чендлер & Джои & Росс',\n",
    "    '(Моника ИЛИ Фиби) & Рэйчел & (Чендлер ИЛИ Джои) & Росс', \n",
    "    '(НЕ Моника) & Фиби & Рэйчел & Чендлер & Джои & (НЕ Росс)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26, 118, 121, 137, 138, 141, 144, 145, 146, 163]\n",
      "[4, 6, 10, 13, 14, 26, 28, 39, 50, 67, 69, 113, 114, 115, 116, 118, 119, 121, 122, 124, 134, 136, 137, 138, 141, 143, 144, 145, 146, 147, 148, 149, 154, 155, 156, 160, 162, 163, 164]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "input_text = [\n",
    "    'Моника & Фиби & Рэйчел & Чендлер & Джоуя & Росс',\n",
    "    '(Моника ИЛИ Фиби) & Рэйчел & (Чендлер ИЛИ Джоуя) & Росс', \n",
    "    '(НЕ Моника) & Фиби & Рэйчел & Чендлер & Джоуя & (НЕ Росс)'\n",
    "]\n",
    "for query in input_text:\n",
    "    print (boolean_search(query, term_doc_matrix, dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pics/inv_index3.svg\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совет для построения обратного индекса: \n",
    "> В качестве словаря используйте ``` defaultdict ``` из модуля collections   \n",
    "Так можно избежать конструкции ``` dict.setdefault(key, default=None) ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index(dictionary, term_doc_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    Create inverted index by input doc collection\n",
    "    :return: inverted index\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for word in dictionary:\n",
    "        result[word] = {key: int(value) for key, value in enumerate(term_doc_matrix[dictionary[word]]) if value > 0}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = inverted_index(dictionary, term_doc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>друг</th>\n",
       "      <th>как</th>\n",
       "      <th>весь</th>\n",
       "      <th>начаться</th>\n",
       "      <th>да</th>\n",
       "      <th>нечего</th>\n",
       "      <th>рассказывать</th>\n",
       "      <th>он</th>\n",
       "      <th>просто</th>\n",
       "      <th>сотрудник</th>\n",
       "      <th>...</th>\n",
       "      <th>асидофилус</th>\n",
       "      <th>прятки</th>\n",
       "      <th>жульничать</th>\n",
       "      <th>хай-я</th>\n",
       "      <th>то,что</th>\n",
       "      <th>iii</th>\n",
       "      <th>карабасос</th>\n",
       "      <th>гардеробный</th>\n",
       "      <th>родственный</th>\n",
       "      <th>объявлять</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 15863 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   друг  как  весь  начаться  да  нечего  рассказывать  он  просто  сотрудник  \\\n",
       "0   1.0   26    43       2.0  20     1.0           1.0  26      20        1.0   \n",
       "1   2.0   21    22       NaN  11     NaN           1.0  20       5        NaN   \n",
       "2   5.0   28    24       NaN  16     NaN           NaN  40       8        NaN   \n",
       "3   5.0   17    29       NaN  14     NaN           NaN  23       3        NaN   \n",
       "4   3.0   27    22       NaN  18     1.0           NaN  26      11        NaN   \n",
       "\n",
       "     ...      асидофилус  прятки  жульничать  хай-я  то,что  iii  карабасос  \\\n",
       "0    ...             NaN     NaN         NaN    NaN     NaN  NaN        NaN   \n",
       "1    ...             NaN     NaN         NaN    NaN     NaN  NaN        NaN   \n",
       "2    ...             NaN     NaN         NaN    NaN     NaN  NaN        NaN   \n",
       "3    ...             NaN     NaN         NaN    NaN     NaN  NaN        NaN   \n",
       "4    ...             NaN     NaN         NaN    NaN     NaN  NaN        NaN   \n",
       "\n",
       "   гардеробный  родственный  объявлять  \n",
       "0          NaN          NaN        NaN  \n",
       "1          NaN          NaN        NaN  \n",
       "2          NaN          NaN        NaN  \n",
       "3          NaN          NaN        NaN  \n",
       "4          NaN          NaN        NaN  \n",
       "\n",
       "[5 rows x 15863 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(index).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью обратного индекса произведите следующую аналитику:  \n",
    "\n",
    "1) общая аналитика\n",
    "- какое слово является самым частотным?\n",
    "- какое самым редким?\n",
    "- какой набор слов есть во всех документах коллекции?\n",
    "\n",
    "2) частота встречаемости имен главных героев в каждом сезоне      \n",
    "- какой сезон был самым популярным у Чендлера? у Моники?   \n",
    "- кто из главных героев статистически самый популярный? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "я 18466\n"
     ]
    }
   ],
   "source": [
    "#частотность max\n",
    "max_word = ''\n",
    "max_occurence = 0\n",
    "for word in index:\n",
    "    n = sum(index[word].values())\n",
    "    if n > max_occurence:\n",
    "        max_word = word\n",
    "        max_occurence = n\n",
    "\n",
    "print (max_word, max_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "придурь 1\n"
     ]
    }
   ],
   "source": [
    "#частотность min\n",
    "min_word = ''\n",
    "min_occurence = float('Inf')\n",
    "for word in index:\n",
    "    n = sum(index[word].values())\n",
    "    if n < min_occurence:\n",
    "        min_word = word\n",
    "        min_occurence = n\n",
    "\n",
    "print (min_word, min_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'как, весь, да, он, просто, ты, на, с, не, мочь, быть, так, у, и, в, я, знать, ну, хотеть, она, что, это, такой, мы, , а, тот, мой, нет, если, этот, о, ещё, но, думать'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#во всей коллекции\n",
    "n = len(files_list)\n",
    "all_docs = []\n",
    "for word in index:\n",
    "    if len(index[word].values()) == n:\n",
    "        all_docs.append(word)\n",
    "', '.join(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "моника 682\n",
      "рэйчел 236\n",
      "фиби 568\n",
      "чендлера 676\n",
      "росс 1015\n",
      "джоуя 682\n"
     ]
    }
   ],
   "source": [
    "#the most popular\n",
    "names = {'моника':['моника'], '':[],'':[],'':[],'':[],'':[],'':[]}\n",
    "for word in ['моника', 'рэйчел', 'фиби', 'чендлера','росс','джоуя']:\n",
    "    print (word, sum(index[word].values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция ранжирования Okapi BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратного индекса есть общепринятая формула для ранжирования *Okapi best match 25* ([Okapi BM25](https://ru.wikipedia.org/wiki/Okapi_BM25)).    \n",
    "Пусть дан запрос $Q$, содержащий слова  $q_1, ... , q_n$, тогда функция BM25 даёт следующую оценку релевантности документа $D$ запросу $Q$:\n",
    "\n",
    "$$ score(D, Q) = \\sum_{i}^{n} \\text{IDF}(q_i)*\\frac{(k_1+1)*f(q_i,D)}{f(q_i,D)+k_1(1-b+b\\frac{|D|}{avgdl})} $$ \n",
    "где   \n",
    ">$f(q_i,D)$ - частота слова $q_i$ в документе $D$ (TF)       \n",
    "$|D|$ - длина документа (количество слов в нём)   \n",
    "*avgdl* — средняя длина документа в коллекции    \n",
    "$k_1$ и $b$ — свободные коэффициенты, обычно их выбирают как $k_1$=2.0 и $b$=0.75   \n",
    "$$$$\n",
    "$\\text{IDF}(q_i)$ есть обратная документная частота (IDF) слова $q_i$: \n",
    "$$\\text{IDF}(q_i) = \\log\\frac{N-n(q_i)+0.5}{n(q_i)+0.5},$$\n",
    ">> где $N$ - общее количество документов в коллекции   \n",
    "$n(q_i)$ — количество документов, содержащих $q_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### реализуйте эту функцию ранжирования \n",
    "from math import log\n",
    "\n",
    "k1 = 2.0\n",
    "b = 0.75\n",
    "\n",
    "def score_BM25(qf, dl, avgdl, k1, b, N, n) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    score = math.log((N-n+0.5)/(n+0.5)) * (k1+1)*qf/(qf+k1*(1-b+b*(dl/avgdl)))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Задача__:    \n",
    "напишите функцию, которая сортирует поисковую выдачу для любого входящего запроса согласно метрике *Okapi BM25*.    \n",
    "Выведите 10 первых результатов и их скор по запросу **рождественские каникулы**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_length = {}\n",
    "for key, value in enumerate(np.transpose(term_doc_matrix)):\n",
    "    doc_length[key] = sum(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sim(word, index, dictionary, term_doc_matrix, doc_length, avgdl, N) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    if word in dictionary:\n",
    "        n = len(index[word])\n",
    "        result = {}\n",
    "        for doc in index[word]:\n",
    "            qf = term_doc_matrix[dictionary[word]][doc]/doc_length[doc]\n",
    "            #qf = term_doc_matrix[dictionary[word]][doc]\n",
    "            score = score_BM25(qf, doc_length[doc], avgdl, k1, b, N, n)\n",
    "            result[doc] = score\n",
    "        return result\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def get_search_result(query) -> list:\n",
    "    \"\"\"\n",
    "    Compute sim score between search query and all documents in collection\n",
    "    Collect as pair (doc_id, score)\n",
    "    :param query: input text\n",
    "    :return: list of lists with (doc_id, score)\n",
    "    \"\"\"\n",
    "    global index, dictionary, term_doc_matrix, doc_length\n",
    "    avgdl = sum(doc_length.values())/len(doc_length)\n",
    "    N = len(doc_length)\n",
    "    result = defaultdict(int)\n",
    "    for word in [morph.parse(word.strip(string.punctuation))[0].normal_form for word in query.split()]:\n",
    "        current = compute_sim(word, index, dictionary, term_doc_matrix, doc_length, avgdl, N)\n",
    "        for doc in current:\n",
    "            result[doc] += current[doc]\n",
    "    result = [('...{}'.format(files_list[key][-45:]), result[key]) for key in islice(sorted(result, key=result.get, reverse=True),10)]\n",
    "    return result\n",
    "    #return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('...0 - The One With The Holiday Armadillo.ru.txt', 0.017704078345142434),\n",
       " (\"...ds - 6x19 - The One With Joey's Fridge.ru.txt\", 0.012635770381949706),\n",
       " ('...ds - 3x10 - The One Where Rachel Quits.ru.txt', 0.00938214309382743),\n",
       " (\"...nds - 2x09 - The One With Phoebe's Dad.ru.txt\", 0.005994620134875919),\n",
       " ('...ds - 1x17 - The One With Two Parts (2).ru.txt', 0.00436499424688355),\n",
       " (\"...iends - 4x03 - The One With The 'Cuffs.ru.txt\", 0.004210559879642346),\n",
       " ('...ds - 1x16 - The One With Two Parts (1).ru.txt', 0.004129113228957865),\n",
       " ('...he One With The Girl From Poughkeepsie.ru.txt', 0.003835774580465368),\n",
       " ('...Friends - 6x12 - The One With The Joke.ru.txt', 0.002282780180675264),\n",
       " ('...s - 6x09 - The One Where Ross Got High.ru.txt', 0.0022075505944722813)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_search_result('рождественские каникулы')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
