{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument, TaggedLineDocument\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "punkt = string.punctuation+'»«–…'\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "from judicial_splitter import splitter\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('qa_corpus.pkl', 'rb') as file:\n",
    "    qa_corpus = pickle.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapdict import heapdict\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, stop=False):\n",
    "    global word_tokenize, stop_words, punkt\n",
    "    text = re.sub(r\"([a-zа-я0-9])(.)([A-ZА-Я0-9])\", r\"\\1\\2 \\3\", text)\n",
    "    text = word_tokenize(text)\n",
    "    new_text= []\n",
    "    for word in text:\n",
    "        word = word.strip(punkt)\n",
    "        if word:\n",
    "            if word in punkt: continue\n",
    "            elif word.isdigit(): continue\n",
    "            elif stop and word in stop_words: continue\n",
    "            else: new_text.append(morph.parse(word)[0].normal_form)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write():\n",
    "    global qa_corpus\n",
    "    with open('d2v_answers_3.txt','w', encoding = 'utf-8') as answers:\n",
    "        with open ('d2v_indexes.txt', 'w', encoding = 'utf-8') as indexes:\n",
    "            with open('d2v_questions.txt', 'w', encoding = 'utf-8') as questions:\n",
    "                for key, value in enumerate(tqdm(qa_corpus)):\n",
    "                    questions.write(' '.join(preprocessing(value[0]))+'\\n')\n",
    "                    for chunk in splitter(value[1], 3):\n",
    "                        answer = ' '.join(preprocessing(chunk))\n",
    "                        if len(answer) > 5:\n",
    "                            answers.write(answer+'\\n')\n",
    "                            indexes.write(str(key)+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Записать всё в предобработанном варианте, чтобы быстрее проверять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10abe67a7ee3445699215995e7eafd81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1384), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итерирование по файлу вместо хранения при обучении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs():\n",
    "    for key, value in enumerate(zip_longest(open('d2v_indexes.txt','r'), open('d2v_answers_3.txt','r'))):\n",
    "        yield TaggedDocument(words=value[1].strip().split(), tags=[int(value[0].strip())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 125 ms, sys: 0 ns, total: 125 ms\n",
      "Wall time: 121 ms\n",
      "2785\n",
      "CPU times: user 4.02 s, sys: 1.15 s, total: 5.16 s\n",
      "Wall time: 3.93 s\n"
     ]
    }
   ],
   "source": [
    "d2v_model = Doc2Vec(vector_size=100, min_count=5, alpha=0.025, seed = 23,\n",
    "                min_alpha=0.025, epochs=1000, workers=8, dm=1)\n",
    "\n",
    "%time d2v_model.build_vocab(docs())\n",
    "print (len(d2v_model.wv.vocab))\n",
    "%time d2v_model.train(docs(), total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model.save('d2v_1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_model = Doc2Vec.load('d2v_1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2v_search(query, n=5):\n",
    "    global d2v_model\n",
    "    d2v_model.random.seed(23)\n",
    "    d2v_vector = d2v_model.infer_vector(query.strip().split(), epochs=1000)\n",
    "    result = {i[0]: i[1] for i in d2v_model.docvecs.most_similar(positive = [d2v_vector], topn=n)}\n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_efficiency_d2v(n = 10):\n",
    "    with open('d2v_questions.txt', 'r') as f:\n",
    "        k = 0\n",
    "        for key, line in enumerate(f):\n",
    "            result = d2v_search(line.strip(), n=n)\n",
    "            if key in result:\n",
    "                k+= 1\n",
    "\n",
    "        print ('top-{}'.format(n), k, k/1384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 6 0.004335260115606936\n",
      "CPU times: user 6min 39s, sys: 9min 43s, total: 16min 22s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%time check_efficiency_d2v(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-10 13 0.00939306358381503\n",
      "CPU times: user 6min 30s, sys: 9min 37s, total: 16min 8s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%time check_efficiency_d2v(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34e8b5fb7734ea9b9922b2052bfd1b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2min 42s, sys: 165 ms, total: 2min 42s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def save_d2v_base():\n",
    "    global d2v_model\n",
    "    with open('d2v_vectors','w', encoding = 'utf-8') as vectors:\n",
    "        for line in tqdm(open('d2v_answers_3.txt','r')):\n",
    "            d2v_model.random.seed(23)\n",
    "            d2v = d2v_model.infer_vector(line.strip().split())\n",
    "            d2v = d2v.tolist()\n",
    "            vectors.write(json.dumps(d2v)+'\\n')\n",
    "%time save_d2v_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2v_search(query, n=10):\n",
    "    global d2v_model\n",
    "    result = heapdict()\n",
    "    d2v_model.random.seed(23)\n",
    "    q_d2v = d2v_model.infer_vector(query.strip().split())\n",
    "    for key, value in enumerate(zip_longest(open('d2v_indexes.txt','r'), open('d2v_vectors','r'))):\n",
    "        d2v = json.loads(value[1])\n",
    "        x = cosine_similarity([q_d2v], [d2v])[0][0]\n",
    "        #print (x)\n",
    "        ordinal = int(value[0])\n",
    "        if ordinal in result:\n",
    "            if result[ordinal] < x:\n",
    "                result[ordinal] = x\n",
    "        else:\n",
    "            if len(result) == n:\n",
    "                z = result.peekitem()\n",
    "                if x > z[1]:\n",
    "                    result.popitem()\n",
    "                    result[ordinal] = x\n",
    "            else:\n",
    "                result[ordinal] = x\n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-5 61 0.04407514450867052\n",
      "CPU times: user 11min 23s, sys: 2.86 s, total: 11min 26s\n",
      "Wall time: 11min 26s\n"
     ]
    }
   ],
   "source": [
    "%time check_efficiency_d2v(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time check_efficiency_d2v(n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_vectors(text, k=300, prep=True):\n",
    "    \"\"\"Получает вектор документа\"\"\"\n",
    "    \n",
    "    global w2v_model, stop_words, word_tokenize\n",
    "    \n",
    "    if prep:\n",
    "        arr_text = preprocessing(text, stop=True)\n",
    "    else:\n",
    "        arr_text = text.split()\n",
    "    n = 0\n",
    "    vector = np.array([0]*300)\n",
    "    \n",
    "    for word in arr_text:\n",
    "        if word not in stop_words:\n",
    "            try:\n",
    "                vec = np.array(w2v_model.wv[word])\n",
    "                n += 1 \n",
    "                vector = vector + vec\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "    if n > 0: vector = vector / n\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('/home/dkbrz/data/rusvectores/araneum_none_fasttextcbow_300_5_2018.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_search(query, n=10):\n",
    "    result = heapdict()\n",
    "    q_w2v = get_w2v_vectors(query, k=300, prep=False)\n",
    "    for key, value in enumerate(zip_longest(open('d2v_indexes.txt','r'), open('w2v_vectors','r'))):\n",
    "        w2v = json.loads(value[1])\n",
    "        x = cosine_similarity([q_w2v], [w2v])[0][0]\n",
    "        #print (x)\n",
    "        ordinal = int(value[0])\n",
    "        if ordinal in result:\n",
    "            if result[ordinal] < x:\n",
    "                result[ordinal] = x\n",
    "        else:\n",
    "            if len(result) == n:\n",
    "                z = result.peekitem()\n",
    "                if x > z[1]:\n",
    "                    result.popitem()\n",
    "                    result[ordinal] = x\n",
    "            else:\n",
    "                result[ordinal] = x\n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad144424fa24361b545dd5e017a6cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 2.32 s, sys: 47.2 ms, total: 2.37 s\n",
      "Wall time: 2.36 s\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def save_w2v_base():\n",
    "    with open('w2v_vectors','w', encoding = 'utf-8') as vectors:\n",
    "        for line in tqdm(open('d2v_answers_3.txt','r')):\n",
    "            w2v = get_w2v_vectors(line.strip(), k=300, prep=False)\n",
    "            w2v = w2v.tolist()\n",
    "            vectors.write(json.dumps(w2v)+'\\n')\n",
    "%time save_w2v_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_efficiency_w2v(n = 10):\n",
    "    with open('d2v_questions.txt', 'r') as f:\n",
    "        k = 0\n",
    "        for key, line in tqdm(enumerate(f)):\n",
    "            result = w2v_search(line.strip(), n=n)\n",
    "            if key in result:\n",
    "                k+= 1\n",
    "\n",
    "        print ('top-{}'.format(n), k, k/1384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531c5285ff25451ab48c79cc9ccfd789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top-5 413 0.2984104046242775\n"
     ]
    }
   ],
   "source": [
    "check_efficiency_w2v(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W2V + TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words={'какой', 'хоть', 'ее', 'после', 'и', 'все', 'том', 'потому', 'была', 'почти', 'нет', 'этот', 'конечно', 'бы', 'тебя', 'больше', 'ли', 'в', 'себя', 'при', 'ведь', 'всю', 'разве', 'надо', 'я', 'до', 'иногда', 'им', 'чего', 'будет', 'можно', 'у', 'нибудь', 'них', 'себе', 'ней', 'какая', 'он..., 'над', 'мой', 'впрочем', 'еще', 'по', 'всех', 'когда', 'может', 'же', 'более', 'про', 'раз', 'за'},\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range = (1,1), stop_words=stop_words)\n",
    "with open ('d2v_answers_3.txt','r') as f:\n",
    "    corpus = f.readlines()\n",
    "tfidf.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_vectors(text, k=300, prep=True):\n",
    "    \"\"\"Получает вектор документа\"\"\"\n",
    "    \n",
    "    global w2v_model, stop_words, word_tokenize, tfidf\n",
    "    \n",
    "    if prep:\n",
    "        arr_text = preprocessing(text, stop=True)\n",
    "    else:\n",
    "        arr_text = text.split()\n",
    "    n = 0\n",
    "    vector = np.array([0]*300)\n",
    "    address = {key:value for key, value in enumerate(tfidf.transform([' '.join(arr_text)]).toarray()[0]) if value != 0}\n",
    "    for word in set(arr_text):\n",
    "        if word not in stop_words:\n",
    "            try:\n",
    "                weight = address[tfidf.vocabulary_[word]]\n",
    "                vec = np.array(w2v_model.wv[word]*weight)\n",
    "                vector = vector + vec\n",
    "                n += weight\n",
    "            except:\n",
    "                continue\n",
    "    if n > 0: vector = vector / n\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27ac927e6c844e1a9bdd0a45f698807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top-5 416 0.30057803468208094\n",
      "CPU times: user 14min 18s, sys: 8.16 s, total: 14min 27s\n",
      "Wall time: 14min 26s\n"
     ]
    }
   ],
   "source": [
    "%time check_efficiency_w2v(n = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OKAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd636062852407ca22f57551bed86b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1384), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def write():\n",
    "    global qa_corpus\n",
    "    with open('ok_answers.txt','w', encoding = 'utf-8') as answers:\n",
    "                for key, value in enumerate(tqdm(qa_corpus)):\n",
    "                        answer = ' '.join(preprocessing(value[1]))\n",
    "                        answers.write(answer+'\\n')\n",
    "write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_doc_matrix():\n",
    "    n = 1384\n",
    "    dictionary = {}\n",
    "    term_doc_matrix = []\n",
    "    for key, item in enumerate(open('ok_answers.txt','r')):\n",
    "        text = Counter(item.strip().split())\n",
    "        for word in text:\n",
    "            if word in dictionary:\n",
    "                term_doc_matrix[dictionary[word]][key] += text[word]\n",
    "            else:\n",
    "                dictionary[word] = len(dictionary)\n",
    "                term_doc_matrix.append(np.zeros(n))\n",
    "                term_doc_matrix[dictionary[word]][key] += text[word]\n",
    "    return dictionary, term_doc_matrix\n",
    "\n",
    "def inverted_index(dictionary, term_doc_matrix) -> dict:\n",
    "    \"\"\"\n",
    "    Create inverted index by input doc collection\n",
    "    :return: inverted index\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for word in dictionary:\n",
    "        result[word] = {key: int(value) for key, value in enumerate(term_doc_matrix[dictionary[word]]) if value > 0}\n",
    "    return result\n",
    "\n",
    "def score_BM25(qf, dl, avgdl, k1, b, N, n) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    score = math.log(1 + (N-n+0.5)/(n+0.5)) * (k1+1)*qf/(qf+k1*(1-b+b*(dl/avgdl)))\n",
    "    return score\n",
    "\n",
    "def compute_sim(word, index, dictionary, term_doc_matrix, doc_length, avgdl, N) -> float:\n",
    "    \"\"\"\n",
    "    Compute similarity score between search query and documents from collection\n",
    "    :return: score\n",
    "    \"\"\"\n",
    "    if word in dictionary:\n",
    "        n = len(index[word])\n",
    "        result = {}\n",
    "        for doc in index[word]:\n",
    "            qf = term_doc_matrix[dictionary[word]][doc]/doc_length[doc]\n",
    "            #qf = term_doc_matrix[dictionary[word]][doc]\n",
    "            score = score_BM25(qf, doc_length[doc], avgdl, k1, b, N, n)\n",
    "            result[doc] = score\n",
    "        return result\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "def get_okapi(query, n = 30) -> float:\n",
    "    \"\"\"\n",
    "    Compute sim score between search query and all documents in collection\n",
    "    Collect as pair (doc_id, score)\n",
    "    :param query: input text\n",
    "    :return: list of lists with (doc_id, score)\n",
    "    \"\"\"\n",
    "    global index, dictionary, term_doc_matrix, doc_length, avgdl, N\n",
    "    query = query.strip().split()\n",
    "    result = defaultdict(int)\n",
    "    for word in query:\n",
    "        current = compute_sim(word, index, dictionary, term_doc_matrix, doc_length, avgdl, N)\n",
    "        for doc in current:\n",
    "            result[doc] += current[doc]\n",
    "    return {i[0]:i[1] for i in sorted(result.items(), key = lambda x: x[1], reverse = True)[:n]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1337: 0.7149959628673017,\n",
       " 698: 0.16460346604070242,\n",
       " 1210: 0.13970408908850643,\n",
       " 29: 0.10047578999633326,\n",
       " 595: 0.09604667442394428,\n",
       " 485: 0.05594133098187612,\n",
       " 295: 0.04325844684583166,\n",
       " 1220: 0.008773665986195623,\n",
       " 516: 0.006735074200899682,\n",
       " 200: 0.0062007226286731965}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_okapi('рф')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary, term_doc_matrix = get_term_doc_matrix()\n",
    "index = inverted_index(dictionary, term_doc_matrix)\n",
    "\n",
    "k1 = 2.0\n",
    "b = 0.75\n",
    "\n",
    "doc_length = {}\n",
    "for key, value in enumerate(np.transpose(term_doc_matrix)):\n",
    "    doc_length[key] = sum(value)\n",
    "\n",
    "avgdl = sum(doc_length.values())/len(doc_length)\n",
    "N = len(doc_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_efficiency_ok(n=5):\n",
    "    with open('d2v_questions.txt', 'r') as f:\n",
    "        k = 0\n",
    "        for key, line in tqdm(enumerate(f)):\n",
    "            result = get_okapi(line.strip(), n=n)\n",
    "            if key in result:\n",
    "                k+= 1\n",
    "\n",
    "        print ('top-{}'.format(n), k, k/1384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b95817caa04caa930f84464b683152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top-5 339 0.24494219653179192\n",
      "CPU times: user 25.1 s, sys: 35 ms, total: 25.1 s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%time check_efficiency_ok(n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_search(query, n=10, prep=True):\n",
    "    if prep: query = ' '.join(preprocessing(query))\n",
    "    w2v = w2v_search(query, n=250)\n",
    "    d2v = d2v_search(query, n=250)\n",
    "    okapi = get_okapi(query, n=250)\n",
    "    candidates = set(w2v) | set(d2v) | set(okapi)\n",
    "    result = heapdict()\n",
    "    #print (candidates)\n",
    "    for i in candidates:\n",
    "        if i in okapi: x = okapi[i]\n",
    "        else: x = 1\n",
    "        coef = 0\n",
    "        if i in w2v: coef += w2v[i]\n",
    "        if i in d2v: coef += d2v[i]\n",
    "        coef = coef*(1+math.log(1 +x))\n",
    "        if len(result) == n and coef > result.peekitem()[1]:\n",
    "            result.popitem()\n",
    "            result[i] = coef*(1+math.log(x))\n",
    "        elif len(result) < n: result[i] = coef*(1+math.log(x))\n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1174: 2.459311588279255,\n",
       " 156: 2.2463586797997133,\n",
       " 1190: 2.321729026265036,\n",
       " 1221: 2.4475711855115523,\n",
       " 244: 2.3837872030075737,\n",
       " 547: 2.267009936939927,\n",
       " 572: 2.403965688945301,\n",
       " 951: 2.513139969047119,\n",
       " 981: 2.2786997432105696,\n",
       " 987: 2.4245083284732454}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_search('закон', n=10, prep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_efficiency_GN(n=5):\n",
    "    with open('d2v_questions.txt', 'r') as f:\n",
    "        k = 0\n",
    "        for key, line in tqdm(enumerate(f)):\n",
    "            result = general_search(line.strip(), n=n, prep=False)\n",
    "            if key in result:\n",
    "                k+= 1\n",
    "\n",
    "        print ('top-{}'.format(n), k, k/1384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "984e59829cb046f3b1dedea61af14a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top-5 246 0.1777456647398844\n"
     ]
    }
   ],
   "source": [
    "check_efficiency_GN(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_search(query, n=10, prep=True):\n",
    "    if prep: query = ' '.join(preprocessing(query))\n",
    "    w2v = w2v_search(query, n=250)\n",
    "    #d2v = d2v_search(query, n=250)\n",
    "    okapi = get_okapi(query, n=250)\n",
    "    #candidates = set(w2v) | set(d2v) | set(okapi)\n",
    "    candidates = set(w2v) | set(okapi)\n",
    "    result = heapdict()\n",
    "    #print (candidates)\n",
    "    for i in candidates:\n",
    "        if i in okapi: x = okapi[i]\n",
    "        else: x = 1\n",
    "        coef = 0\n",
    "        if i in w2v: coef += w2v[i]\n",
    "        #if i in d2v: coef += d2v[i]\n",
    "        coef = coef*(1+math.log(1 +x))\n",
    "        if len(result) == n and coef > result.peekitem()[1]:\n",
    "            result.popitem()\n",
    "            result[i] = coef*(1+math.log(x))\n",
    "        elif len(result) < n: result[i] = coef*(1+math.log(x))\n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc228fe22db34f1b87c433094768c127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top-5 432 0.31213872832369943\n"
     ]
    }
   ],
   "source": [
    "check_efficiency_GN(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_search(query, n=10, prep=True):\n",
    "    if prep: query = ' '.join(preprocessing(query))\n",
    "    w2v = w2v_search(query, n=500)\n",
    "    #d2v = d2v_search(query, n=250)\n",
    "    okapi = get_okapi(query, n=500)\n",
    "    #candidates = set(w2v) | set(d2v) | set(okapi)\n",
    "    candidates = set(w2v) | set(okapi)\n",
    "    result = heapdict()\n",
    "    #print (candidates)\n",
    "    for i in candidates:\n",
    "        if i in okapi: x = okapi[i]\n",
    "        else: x = 1\n",
    "        coef = 0\n",
    "        if i in w2v: coef += w2v[i]\n",
    "        #if i in d2v: coef += d2v[i]\n",
    "        coef = coef*(1+math.log(1 +x))\n",
    "        if len(result) == n and coef > result.peekitem()[1]:\n",
    "            result.popitem()\n",
    "            result[i] = coef*(1+math.log(x))\n",
    "        elif len(result) < n: result[i] = coef*(1+math.log(x))\n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0464695965994877a14f708b1249cfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top-5 432 0.31213872832369943\n"
     ]
    }
   ],
   "source": [
    "check_efficiency_GN(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_search(query, n=10, prep=True):\n",
    "    if prep: query = ' '.join(preprocessing(query))\n",
    "    w2v = w2v_search(query, n=500)\n",
    "    #d2v = d2v_search(query, n=250)\n",
    "    okapi = get_okapi(query, n=500)\n",
    "    #candidates = set(w2v) | set(d2v) | set(okapi)\n",
    "    candidates = set(w2v) | set(okapi)\n",
    "    result = heapdict()\n",
    "    #print (candidates)\n",
    "    for i in candidates:\n",
    "        if i in okapi: x = okapi[i]\n",
    "        else: x = 1\n",
    "        coef = 0\n",
    "        if i in w2v: coef += w2v[i]\n",
    "        #if i in d2v: coef += d2v[i]\n",
    "        coef = math.exp(coef)*x\n",
    "        if len(result) == n and coef > result.peekitem()[1]:\n",
    "            result.popitem()\n",
    "            result[i] = coef*(1+math.log(x))\n",
    "        elif len(result) < n: result[i] = coef*(1+math.log(x))\n",
    "    return dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609f42c2e6954083af17b3a52df61305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top-5 324 0.23410404624277456\n"
     ]
    }
   ],
   "source": [
    "check_efficiency_GN(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3498588075760032"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6094379124341003"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
